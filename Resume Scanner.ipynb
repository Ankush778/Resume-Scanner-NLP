{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0ae4e5-73bd-4802-938f-0d7f05f61440",
   "metadata": {},
   "source": [
    "# Resume Scanner"
   ]
  },
  {
   "cell_type": "raw",
   "id": "240cd0e8-5209-445c-8bb1-8e5388ecafbb",
   "metadata": {},
   "source": [
    "Goal : Automatically screen resumes to find the most relevant candidate for a given job description.\n",
    "Input : PDF or text resumes A job Description.\n",
    "Output : Ranked list of candidates on similarity with the JD optional : classification(e.g. \"Highly Relevant\", \"Moderate\", \"Low\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5df4b0-1b4a-4e5c-9d10-9ad901abd780",
   "metadata": {},
   "source": [
    "# Step 1 : Extract Text from resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd30c126-f6d8-4506-a2c4-19b5c37335d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e4ec37-2bfe-4266-8fc5-9b57566171cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pdf or text file from a folder\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \" \"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "folder = 'Resumes/'\n",
    "resumes = {}\n",
    "for file in os.listdir('Resumes/'):\n",
    "    if file.endswith('.pdf'):\n",
    "        resumes[file] = extract_text_from_pdf(os.path.join(folder, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0137ee0-e6eb-4449-bce2-9c990d6241b1",
   "metadata": {},
   "source": [
    "# Step 2: Preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635da5fa-849f-4bdf-a0d3-0764e5c11aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and normalize both the resume text and job description.\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb59414-90cb-4fdd-ae9d-85e3c1a1918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65dfdf0e-befe-4fc7-8b83-d83f0a068edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "153238e9-e9b1-40ad-99b6-60a5e68ea88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text) # this line will help to keep only numbers\n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa28d4-259b-4f29-9956-d671c2bd6e19",
   "metadata": {},
   "source": [
    "# Step 3 : Convert text to numerical vector(TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c11fcc3-13fd-49f4-98e0-0fb06c4b5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TF-IDF to represent text for comparison\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "jd = \"\"\" Biocube is looking for Data Scientist to join our dynamic team and embark on a rewarding career journey\n",
    "Undertaking data collection, preprocessing and analysis\n",
    "Building models to address business problems\n",
    "Presenting information using data visualization techniques\n",
    "Identify valuable data sources and automate collection processes\n",
    "Undertake preprocessing of structured and unstructured data\n",
    "Analyze large amounts of information to discover trends and patterns\n",
    "Build predictive models and machine-learning algorithms\n",
    "Combine models through ensemble modeling\n",
    "Present information using data visualization techniques\n",
    "Propose solutions and strategies to business challenges\n",
    "Collaborate with engineering and product development teams \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fc3733-58c0-49f6-b78b-b0014503a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [preprocess_text(jd)] + [preprocess_text(text) for text in resumes.values()]\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd6510-53f0-44d3-9491-e614a54fb651",
   "metadata": {},
   "source": [
    "# Step 4 : Compute similarity between Job description and Each resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d06a7c40-d4ca-4eea-8541-ff792248f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7768705-529d-48c4-adf3-5c6594561e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankush_Bhonde_DA.pdf : 0.19\n",
      "Ankush_Bhonde_Data_Science.pdf : 0.19\n",
      "Ankush_Bhonde_DS.pdf : 0.19\n"
     ]
    }
   ],
   "source": [
    "similarity_score = cosine_similarity(vectors[0:1], vectors[1:]).flatten()\n",
    "\n",
    "for i, (filename, score) in enumerate(zip(resumes.keys(), similarity_score)):\n",
    "    print(f\"{filename} : {score :.2f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f1371a-6324-44d2-af61-366d75e6017f",
   "metadata": {},
   "source": [
    "# Step 5 : Rank the Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82fe8685-2e02-45c4-b3bc-939610e82faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Resume  Similarity\n",
      "0            Ankush_Bhonde_DA.pdf    0.192588\n",
      "1  Ankush_Bhonde_Data_Science.pdf    0.186466\n",
      "2            Ankush_Bhonde_DS.pdf    0.186144\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame({\n",
    "    \"Resume\" : list(resumes.keys()),\n",
    "    \"Similarity\" : similarity_score\n",
    "}).sort_values(by = \"Similarity\", ascending = False)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea86768-1524-4023-a4bb-34fcfe307241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
